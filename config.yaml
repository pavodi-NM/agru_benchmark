# =============================================================================
# RNN Benchmark Configuration File
# Comparing LSTM, GRU, and Antisymmetric GRU (A-GRU)
# =============================================================================

# -----------------------------------------------------------------------------
# Dataset Configuration
# -----------------------------------------------------------------------------
dataset:
  name: "sequential_mnist"  # Options: sequential_mnist, har, lorenz
  description: "Sequential MNIST - row-by-row pixel classification"
  
  # Sequential MNIST specific settings
  sequential_mnist:
    # Each image is treated as a sequence of 28 rows, each row has 28 pixels
    sequence_length: 28
    input_size: 28
    num_classes: 10
    # Data will be downloaded to this directory
    data_dir: "./data"
    
  # Preprocessing
  preprocessing:
    normalize: true
    normalization_method: "minmax"  # Options: minmax, zscore
    
  # Data splits
  splits:
    train_ratio: 0.85
    val_ratio: 0.15
    # Test set is predefined in Sequential MNIST

# -----------------------------------------------------------------------------
# Training Configuration
# -----------------------------------------------------------------------------
training:
  # Reproducibility
  seed: 42
  deterministic: true
  
  # Training parameters
  num_epochs: 150 # 50
  batch_size: 128
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 10
    min_delta: 0.0001
    monitor: "val_loss"
    
  # Gradient clipping (important for RNN stability)
  gradient_clipping:
    enabled: true
    max_norm: 1.0
    
  # Learning rate scheduling
  lr_scheduler:
    enabled: true
    type: "reduce_on_plateau"  # Options: reduce_on_plateau, step, cosine
    factor: 0.5
    patience: 5
    min_lr: 0.00001

# -----------------------------------------------------------------------------
# Optimization Configuration
# -----------------------------------------------------------------------------
optimization:
  optimizer: "adam"  # Options: adam, sgd, rmsprop, adamw
  learning_rate: 0.001
  weight_decay: 0.0001
  
  # Adam specific parameters
  adam:
    betas: [0.9, 0.999]
    eps: 0.00000001
    
  # SGD specific parameters (if used)
  sgd:
    momentum: 0.9
    nesterov: true

# -----------------------------------------------------------------------------
# Loss Function Configuration
# -----------------------------------------------------------------------------
loss:
  type: "cross_entropy"  # Options: cross_entropy, mse, mae
  label_smoothing: 0.0

# -----------------------------------------------------------------------------
# Model Configurations
# -----------------------------------------------------------------------------
models:
  # Common settings for all models
  common:
    num_layers: 1
    hidden_size: 128
    dropout: 0.0
    bidirectional: false
    
  # LSTM-specific configuration
  lstm:
    enabled: true
    hidden_size: 128
    num_layers: 1
    dropout: 0.0
    bidirectional: false
    # Weight initialization
    weight_init:
      type: "xavier_uniform"  # Options: xavier_uniform, xavier_normal, orthogonal, default
      
  # GRU-specific configuration
  gru:
    enabled: true
    hidden_size: 128
    num_layers: 1
    dropout: 0.0
    bidirectional: false
    # Weight initialization
    weight_init:
      type: "xavier_uniform"
      
  # A-GRU (Antisymmetric GRU) specific configuration
  agru:
    enabled: true
    hidden_size: 128
    num_layers: 1
    dropout: 0.0
    # Antisymmetric specific parameters
    gamma: 2.0 # Diffusion coefficient for stability (Î³I term)
    epsilon: 1.0  # Global step size for dynamics scaling
    learnable_epsilon: true  # Whether epsilon is learnable
    # Weight initialization
    weight_init:
      type: "xavier_uniform"
    # Numerical stabilization
    stability:
      use_layer_norm: false
      clip_hidden: false
      clip_value: 10.0

# -----------------------------------------------------------------------------
# Evaluation Configuration
# -----------------------------------------------------------------------------
evaluation:
  # Metrics to compute
  metrics:
    - accuracy
    - precision
    - recall
    - f1_score
    
  # Number of runs for statistical significance
  num_runs: 5
  
  # Compute confidence intervals
  confidence_interval: 0.95

# -----------------------------------------------------------------------------
# Logging and Visualization
# -----------------------------------------------------------------------------
logging:
  # Console logging
  log_interval: 100  # Print every N batches
  verbose: true
  
  # File logging
  save_logs: true
  log_dir: "./results/logs"
  
  # Model checkpointing
  checkpointing:
    enabled: true
    save_best_only: true
    checkpoint_dir: "./results/checkpoints"

visualization:
  # Plot settings
  save_plots: true
  plot_dir: "./results/plots"
  plot_format: "png"  # Options: png, pdf, svg
  dpi: 300
  
  # What to plot
  plots:
    - training_curves
    - validation_curves
    - comparison_bar
    - confusion_matrix
    
  # Style settings
  style:
    figure_size: [10, 6]
    font_size: 12
    use_grid: true
    color_palette: "Set2"

# -----------------------------------------------------------------------------
# Hardware Configuration
# -----------------------------------------------------------------------------
hardware:
  device: "auto"  # Options: auto, cuda, cpu
  num_workers: 4
  pin_memory: true
